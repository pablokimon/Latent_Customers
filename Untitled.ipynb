{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import rainbow\n",
    "import os\n",
    "import glob\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "\n",
    "def json_to_df(path):\n",
    "    all_files = glob.glob(os.path.join(path, \"*.json\"))\n",
    "    df = pd.concat((pd.read_json(f,keep_default_dates=False,lines=True) for f in all_files)) \n",
    "    return df\n",
    "def get_items(df,most_common=50,least_common=5):\n",
    "\n",
    "    '''build a dictionary where the keys are the words\n",
    "    in the dataframe items column'''\n",
    "    item_dict = defaultdict(int)\n",
    "    for basket in df['items']:\n",
    "        if basket:\n",
    "            for item in basket:\n",
    "                if item:\n",
    "                    item_dict[item[1]] += 1   \n",
    "    '''add the most common words to the stopwords list'''\n",
    "    stopwords = list([i[0] for i in Counter(item_dict).most_common(most_common)])\n",
    "    '''add the least common words to the stopwords list'''\n",
    "    for key,value in item_dict.items():\n",
    "        if value <5:\n",
    "            stopwords.append(key)\n",
    "\n",
    "    '''iterate through the baskets and add items to items_set\n",
    "    if not in stopwords (too common or too uncommon)'''\n",
    "    items = []\n",
    "    for basket in df['items']:\n",
    "        for item in basket:\n",
    "            if item[1] in stopwords:\n",
    "                continue\n",
    "            else:\n",
    "                items.append(item[1])\n",
    "    items_set=set(items)\n",
    "\n",
    "    return items_set,stopwords\n",
    "\n",
    "def build_matrix(df,items_set):\n",
    "\n",
    "    item_matrix = np.zeros((df.shape[0],len(items_set)))\n",
    "    df_items= pd.DataFrame(item_matrix,columns=items_set)\n",
    "    df=df.reset_index()\n",
    "    df.pop('index')\n",
    "    col_index_dict = dict(zip(items_set, range(len(items_set))))\n",
    "    matrix = np.zeros(df_items.shape)\n",
    "    #iterate through all rows and insert value of item at row of basket and column of item\n",
    "    for i in range(df.shape[0]):\n",
    "        for item in df['items'][i]:\n",
    "            #set matrix to boolean for item precence in basket:\n",
    "            if item[1] not in stopwords:\n",
    "                matrix[i,col_index_dict[ item[1] ]] = matrix[i,col_index_dict[ item[1] ]] + item[2]\n",
    "            '''if item[1] not in stopwords and item[2] > 0:\n",
    "                matrix[i,col_index_dict[ item[1] ]] = 1\n",
    "            if item[1] not in stopwords and item[2] < 0:\n",
    "                matrix[i,col_index_dict[ item[1] ]] = 0'''\n",
    "    matrix = (matrix > 0).astype(int)\n",
    "    return matrix\n",
    "def fit_model(sparse_matrix,n_components=10):\n",
    "\n",
    "    model = NMF(n_components=n_components)\n",
    "    W = model.fit_transform(sparse_matrix)\n",
    "    H=model.components_\n",
    "    return model,W,H\n",
    "\n",
    "def print_top_items(model, feature_names, n_top_words):\n",
    "    topics =[]\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        #topic_string=(\" \".join([feature_names[i]for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        topic_string=str([feature_names[i]for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "\n",
    "        topics.append(topic_string)\n",
    "        print(topic_string)\n",
    "        #print()\n",
    "        wordcloud = WordCloud(max_font_size=500, max_words=1000, background_color=\"white\").generate(topic_string.replace(\" \", \"_\").replace(\"'\",\"\"))\n",
    "\n",
    "        # Display the generated image:\n",
    "        plt.figure(1,figsize=(10,10))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        #plt.savefig('topic%d.png'%topic_idx)\n",
    "        #plt.close()\n",
    "        wordcloud.to_file('topic%d.png'%topic_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_components = 10\n",
    "\n",
    "df = json_to_df('/Users/Sarah/galvanize/dsi-capstone/jsons/')\n",
    "\n",
    "items_set,stopwords = get_items(df,most_common=25,least_common=10)\n",
    "\n",
    "matrix = build_matrix(df,items_set)\n",
    "\n",
    "sparse_matrix = sparse.csr_matrix(matrix)\n",
    "\n",
    "model,W,H = fit_model(sparse_matrix,n_components)\n",
    "\n",
    "print_top_items(model,list(items_set),20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
